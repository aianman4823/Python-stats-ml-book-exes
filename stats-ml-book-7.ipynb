{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba714960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c992666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ttest_1samp in module scipy.stats.stats:\n",
      "\n",
      "ttest_1samp(a, popmean, axis=0, nan_policy='propagate', alternative='two-sided')\n",
      "    Calculate the T-test for the mean of ONE group of scores.\n",
      "    \n",
      "    This is a two-sided test for the null hypothesis that the expected value\n",
      "    (mean) of a sample of independent observations `a` is equal to the given\n",
      "    population mean, `popmean`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Sample observation.\n",
      "    popmean : float or array_like\n",
      "        Expected value in null hypothesis. If array_like, then it must have the\n",
      "        same shape as `a` excluding the axis dimension.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to compute test; default is 0. If None, compute over\n",
      "        the whole array `a`.\n",
      "    nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "        Defines how to handle when input contains nan.\n",
      "        The following options are available (default is 'propagate'):\n",
      "    \n",
      "          * 'propagate': returns nan\n",
      "          * 'raise': throws an error\n",
      "          * 'omit': performs the calculations ignoring nan values\n",
      "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is 'two-sided'):\n",
      "    \n",
      "          * 'two-sided'\n",
      "          * 'less': one-sided\n",
      "          * 'greater': one-sided\n",
      "    \n",
      "        .. versionadded:: 1.6.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        t-statistic.\n",
      "    pvalue : float or array\n",
      "        Two-sided p-value.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import stats\n",
      "    \n",
      "    >>> np.random.seed(7654567)  # fix seed to get the same result\n",
      "    >>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50,2))\n",
      "    \n",
      "    Test if mean of random sample is equal to true mean, and different mean.\n",
      "    We reject the null hypothesis in the second case and don't reject it in\n",
      "    the first case.\n",
      "    \n",
      "    >>> stats.ttest_1samp(rvs,5.0)\n",
      "    (array([-0.68014479, -0.04323899]), array([ 0.49961383,  0.96568674]))\n",
      "    >>> stats.ttest_1samp(rvs,0.0)\n",
      "    (array([ 2.77025808,  4.11038784]), array([ 0.00789095,  0.00014999]))\n",
      "    \n",
      "    Examples using axis and non-scalar dimension for population mean.\n",
      "    \n",
      "    >>> result = stats.ttest_1samp(rvs, [5.0, 0.0])\n",
      "    >>> result.statistic\n",
      "    array([-0.68014479,  4.11038784]),\n",
      "    >>> result.pvalue\n",
      "    array([4.99613833e-01, 1.49986458e-04])\n",
      "    \n",
      "    >>> result = stats.ttest_1samp(rvs.T, [5.0, 0.0], axis=1)\n",
      "    >>> result.statistic\n",
      "    array([-0.68014479,  4.11038784])\n",
      "    >>> result.pvalue\n",
      "    array([4.99613833e-01, 1.49986458e-04])\n",
      "    \n",
      "    >>> result = stats.ttest_1samp(rvs, [[5.0], [0.0]])\n",
      "    >>> result.statistic\n",
      "    array([[-0.68014479, -0.04323899],\n",
      "           [ 2.77025808,  4.11038784]])\n",
      "    >>> result.pvalue\n",
      "    array([[4.99613833e-01, 9.65686743e-01],\n",
      "           [7.89094663e-03, 1.49986458e-04]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(stats.ttest_1samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "024cd241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = np.random.normal(loc = 1.1, size = 50)\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac30a945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734133639234073"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z, pval = stats.ttest_1samp(dat, popmean=1.0)\n",
    "# Zは検定統計量(今回は期待値loc = 1.1に近い値になるはず)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5cbc3965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3351289475316437"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74fe7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.random.normal(loc = 1.1, size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "555955a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0596231464479188"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z, pval = stats.ttest_1samp(dat, 1.0)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0bc27cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525156152817686"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa20a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttest_1sampには片側検定がないので両側検定から求める\n",
    "dat = np.random.normal(loc = 1.1, size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b74444c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.36446446411445"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z, pval = stats.ttest_1samp(dat, 1.0)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ff433be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01901868519278515"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "349a5849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009509342596392575"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 片側検定(Z > 0)\n",
    "pval/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3158fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2標本検定\n",
    "# statsにはttest_indに2標本検定を行う関数がある\n",
    "# データの生成\n",
    "x = np.random.normal(loc = 1.1, size = 100)\n",
    "y = np.random.normal(loc = 1.0, size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0f4ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5473522216695064 0.5843409844130166\n"
     ]
    }
   ],
   "source": [
    "# x, yの分散が等しいと仮定\n",
    "Z, pval = stats.ttest_ind(x, y)\n",
    "print(Z, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aefe9203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5575204857589618 0.5780375552227384\n"
     ]
    }
   ],
   "source": [
    "# x, yの分散が異なると仮定\n",
    "Z, pval = stats.ttest_ind(x, y, equal_var=False)\n",
    "print(Z, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6cd6034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ペアの情報の検定\n",
    "# 1. 一つのものとして検定\n",
    "# 2. 2標本として検定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "89a12326",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(loc = 1.1, scale = 1, size = 1000)\n",
    "y = np.random.normal(loc = 1.0, scale = 1.1, size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f98a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 2.0843300199540873\n",
      "pval: 0.0372585634611266\n"
     ]
    }
   ],
   "source": [
    "# 2標本検定: 等分散を仮定しない\n",
    "Z, pval = stats.ttest_ind(x, y, equal_var=False)\n",
    "print(\"Z: {0}\\npval: {1}\".format(Z, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04132867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 2.0843300199540873\n",
      "pval: 0.037256900928186086\n"
     ]
    }
   ],
   "source": [
    "# 2標本検定: 等分散を仮定\n",
    "Z, pval = stats.ttest_ind(x, y)\n",
    "print(\"Z: {0}\\npval: {1}\".format(Z, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3d232e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 2.1083797741563606\n",
      "pval: 0.03524665846548258\n"
     ]
    }
   ],
   "source": [
    "# 2標本をペアとして検定\n",
    "Z, pval = stats.ttest_rel(x, y)\n",
    "print(\"Z: {0}\\npval: {1}\".format(Z, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9bbbd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 2.1083797741563606\n",
      "pval: 0.03524665846548258\n"
     ]
    }
   ],
   "source": [
    "# 2標本をペアとして検定: データを1つに変換させたのち検定\n",
    "# μ1 = μ2をH0としている\n",
    "Z, pval = stats.ttest_1samp(x - y, 0)\n",
    "print(\"Z: {0}\\npval: {1}\".format(Z, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f52c82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mannwhitneyu in module scipy.stats.stats:\n",
      "\n",
      "mannwhitneyu(x, y, use_continuity=True, alternative=None)\n",
      "    Compute the Mann-Whitney rank test on samples x and y.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x, y : array_like\n",
      "        Array of samples, should be one-dimensional.\n",
      "    use_continuity : bool, optional\n",
      "            Whether a continuity correction (1/2.) should be taken into\n",
      "            account. Default is True.\n",
      "    alternative : {None, 'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is None):\n",
      "    \n",
      "          * None: computes p-value half the size of the 'two-sided' p-value and\n",
      "            a different U statistic. The default behavior is not the same as\n",
      "            using 'less' or 'greater'; it only exists for backward compatibility\n",
      "            and is deprecated.\n",
      "          * 'two-sided'\n",
      "          * 'less': one-sided\n",
      "          * 'greater': one-sided\n",
      "    \n",
      "        Use of the None option is deprecated.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float\n",
      "        The Mann-Whitney U statistic, equal to min(U for x, U for y) if\n",
      "        `alternative` is equal to None (deprecated; exists for backward\n",
      "        compatibility), and U for y otherwise.\n",
      "    pvalue : float\n",
      "        p-value assuming an asymptotic normal distribution. One-sided or\n",
      "        two-sided, depending on the choice of `alternative`.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Use only when the number of observation in each sample is > 20 and\n",
      "    you have 2 independent samples of ranks. Mann-Whitney U is\n",
      "    significant if the u-obtained is LESS THAN or equal to the critical\n",
      "    value of U.\n",
      "    \n",
      "    This test corrects for ties and by default uses a continuity correction.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] https://en.wikipedia.org/wiki/Mann-Whitney_U_test\n",
      "    \n",
      "    .. [2] H.B. Mann and D.R. Whitney, \"On a Test of Whether one of Two Random\n",
      "           Variables is Stochastically Larger than the Other,\" The Annals of\n",
      "           Mathematical Statistics, vol. 18, no. 1, pp. 50-60, 1947.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ノンパラメトリックな検定手法\n",
    "# マンホイットニーのU検定\n",
    "help(stats.mannwhitneyu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e90c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例1: 同じ分布に従う標本\n",
    "x = np.random.normal(loc = 1, size = 500)\n",
    "y = np.random.normal(loc = 1, size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7cb7b24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 70753.0\n",
      "pval: 0.1795886335433372\n"
     ]
    }
   ],
   "source": [
    "# 両側検定\n",
    "r, pval = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "print(\"r: {}\\npval: {}\".format(r, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99dbe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例２: 同じ期待値の分布に従う標本(分布は異なる)\n",
    "x = np.random.normal(loc = 1, scale = 2, size = 500)\n",
    "y = np.random.normal(loc = 1, scale = 1, size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ffe389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 71855.0\n",
      "pval: 0.32034103612897236\n"
     ]
    }
   ],
   "source": [
    "# 両側検定\n",
    "r, pval = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "print(\"r: {}\\npval: {}\".format(r, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ddfce5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例3: 異なる期待値の分布に従う標本\n",
    "x = np.random.normal(loc = 1.2, size = 500)\n",
    "y = np.random.normal(loc = 1, size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f89a5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 87921.0\n",
      "pval: 4.4406453799898546e-05\n"
     ]
    }
   ],
   "source": [
    "# 両側検定\n",
    "r, pval = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "print(\"r: {}\\npval: {}\".format(r, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c38a3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x, bins = 50)\n",
    "plt.hist(y, bins = 50)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aa675a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ks_2samp in module scipy.stats.stats:\n",
      "\n",
      "ks_2samp(data1, data2, alternative='two-sided', mode='auto')\n",
      "    Compute the Kolmogorov-Smirnov statistic on 2 samples.\n",
      "    \n",
      "    This is a two-sided test for the null hypothesis that 2 independent samples\n",
      "    are drawn from the same continuous distribution.  The alternative hypothesis\n",
      "    can be either 'two-sided' (default), 'less' or 'greater'.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data1, data2 : array_like, 1-Dimensional\n",
      "        Two arrays of sample observations assumed to be drawn from a continuous\n",
      "        distribution, sample sizes can be different.\n",
      "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is 'two-sided'):\n",
      "    \n",
      "          * 'two-sided'\n",
      "          * 'less': one-sided, see explanation in Notes\n",
      "          * 'greater': one-sided, see explanation in Notes\n",
      "    mode : {'auto', 'exact', 'asymp'}, optional\n",
      "        Defines the method used for calculating the p-value.\n",
      "        The following options are available (default is 'auto'):\n",
      "    \n",
      "          * 'auto' : use 'exact' for small size arrays, 'asymp' for large\n",
      "          * 'exact' : use exact distribution of test statistic\n",
      "          * 'asymp' : use asymptotic distribution of test statistic\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float\n",
      "        KS statistic.\n",
      "    pvalue : float\n",
      "        Two-tailed p-value.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    kstest, ks_1samp, epps_singleton_2samp, anderson_ksamp\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This tests whether 2 samples are drawn from the same distribution. Note\n",
      "    that, like in the case of the one-sample KS test, the distribution is\n",
      "    assumed to be continuous.\n",
      "    \n",
      "    In the one-sided test, the alternative is that the empirical\n",
      "    cumulative distribution function F(x) of the data1 variable is \"less\"\n",
      "    or \"greater\" than the empirical cumulative distribution function G(x)\n",
      "    of the data2 variable, ``F(x)<=G(x)``, resp. ``F(x)>=G(x)``.\n",
      "    \n",
      "    If the KS statistic is small or the p-value is high, then we cannot\n",
      "    reject the hypothesis that the distributions of the two samples\n",
      "    are the same.\n",
      "    \n",
      "    If the mode is 'auto', the computation is exact if the sample sizes are\n",
      "    less than 10000.  For larger sizes, the computation uses the\n",
      "    Kolmogorov-Smirnov distributions to compute an approximate value.\n",
      "    \n",
      "    The 'two-sided' 'exact' computation computes the complementary probability\n",
      "    and then subtracts from 1.  As such, the minimum probability it can return\n",
      "    is about 1e-16.  While the algorithm itself is exact, numerical\n",
      "    errors may accumulate for large sample sizes.   It is most suited to\n",
      "    situations in which one of the sample sizes is only a few thousand.\n",
      "    \n",
      "    We generally follow Hodges' treatment of Drion/Gnedenko/Korolyuk [1]_.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Hodges, J.L. Jr.,  \"The Significance Probability of the Smirnov\n",
      "           Two-Sample Test,\" Arkiv fiur Matematik, 3, No. 43 (1958), 469-86.\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import stats\n",
      "    >>> np.random.seed(12345678)  #fix random seed to get the same result\n",
      "    >>> n1 = 200  # size of first sample\n",
      "    >>> n2 = 300  # size of second sample\n",
      "    \n",
      "    For a different distribution, we can reject the null hypothesis since the\n",
      "    pvalue is below 1%:\n",
      "    \n",
      "    >>> rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1)\n",
      "    >>> rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5)\n",
      "    >>> stats.ks_2samp(rvs1, rvs2)\n",
      "    (0.20833333333333334, 5.129279597781977e-05)\n",
      "    \n",
      "    For a slightly different distribution, we cannot reject the null hypothesis\n",
      "    at a 10% or lower alpha since the p-value at 0.144 is higher than 10%\n",
      "    \n",
      "    >>> rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0)\n",
      "    >>> stats.ks_2samp(rvs1, rvs3)\n",
      "    (0.10333333333333333, 0.14691437867433876)\n",
      "    \n",
      "    For an identical distribution, we cannot reject the null hypothesis since\n",
      "    the p-value is high, 41%:\n",
      "    \n",
      "    >>> rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0)\n",
      "    >>> stats.ks_2samp(rvs1, rvs4)\n",
      "    (0.07999999999999996, 0.41126949729859719)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# コルモゴロフ-スミルノフ(KS)検定\n",
    "# KS検定では分布の違いを検出できる\n",
    "help(stats.ks_2samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5cb8561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS検定ではU検定とは異なり、同じ期待値を持つ異なる分布の違いを検出できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55722df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同じ分布に従う標本\n",
    "x = np.random.normal(loc = 1, size = 500)\n",
    "y = np.random.normal(loc = 1, size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c3644ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: 0.042\n",
      "pval: 0.8827463499336298\n"
     ]
    }
   ],
   "source": [
    "D, pval = stats.ks_2samp(x, y)\n",
    "print(\"D: {}\\npval: {}\".format(D, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b0a429a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同じ期待値で分散が異なる分布に従う標本\n",
    "x = np.random.normal(loc = 1, scale = 2, size = 500)\n",
    "y = np.random.normal(loc = 1, size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "68a8e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: 0.21533333333333332\n",
      "pval: 4.383633711579904e-08\n"
     ]
    }
   ],
   "source": [
    "D, pval = stats.ks_2samp(x, y)\n",
    "print(\"D: {}\\npval: {}\".format(D, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bde3ee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function f_oneway in module scipy.stats.stats:\n",
      "\n",
      "f_oneway(*args, axis=0)\n",
      "    Perform one-way ANOVA.\n",
      "    \n",
      "    The one-way ANOVA tests the null hypothesis that two or more groups have\n",
      "    the same population mean.  The test is applied to samples from two or\n",
      "    more groups, possibly with differing sizes.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sample1, sample2, ... : array_like\n",
      "        The sample measurements for each group.  There must be at least\n",
      "        two arguments.  If the arrays are multidimensional, then all the\n",
      "        dimensions of the array must be the same except for `axis`.\n",
      "    axis : int, optional\n",
      "        Axis of the input arrays along which the test is applied.\n",
      "        Default is 0.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float\n",
      "        The computed F statistic of the test.\n",
      "    pvalue : float\n",
      "        The associated p-value from the F distribution.\n",
      "    \n",
      "    Warns\n",
      "    -----\n",
      "    F_onewayConstantInputWarning\n",
      "        Raised if each of the input arrays is constant array.\n",
      "        In this case the F statistic is either infinite or isn't defined,\n",
      "        so ``np.inf`` or ``np.nan`` is returned.\n",
      "    \n",
      "    F_onewayBadInputSizesWarning\n",
      "        Raised if the length of any input array is 0, or if all the input\n",
      "        arrays have length 1.  ``np.nan`` is returned for the F statistic\n",
      "        and the p-value in these cases.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The ANOVA test has important assumptions that must be satisfied in order\n",
      "    for the associated p-value to be valid.\n",
      "    \n",
      "    1. The samples are independent.\n",
      "    2. Each sample is from a normally distributed population.\n",
      "    3. The population standard deviations of the groups are all equal.  This\n",
      "       property is known as homoscedasticity.\n",
      "    \n",
      "    If these assumptions are not true for a given set of data, it may still\n",
      "    be possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`)\n",
      "    although with some loss of power.\n",
      "    \n",
      "    The length of each group must be at least one, and there must be at\n",
      "    least one group with length greater than one.  If these conditions\n",
      "    are not satisfied, a warning is generated and (``np.nan``, ``np.nan``)\n",
      "    is returned.\n",
      "    \n",
      "    If each group contains constant values, and there exist at least two\n",
      "    groups with different values, the function generates a warning and\n",
      "    returns (``np.inf``, 0).\n",
      "    \n",
      "    If all values in all groups are the same, function generates a warning\n",
      "    and returns (``np.nan``, ``np.nan``).\n",
      "    \n",
      "    The algorithm is from Heiman [2]_, pp.394-7.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. Lowry, \"Concepts and Applications of Inferential Statistics\",\n",
      "           Chapter 14, 2014, http://vassarstats.net/textbook/\n",
      "    \n",
      "    .. [2] G.W. Heiman, \"Understanding research methods and statistics: An\n",
      "           integrated introduction for psychology\", Houghton, Mifflin and\n",
      "           Company, 2001.\n",
      "    \n",
      "    .. [3] G.H. McDonald, \"Handbook of Biological Statistics\", One-way ANOVA.\n",
      "           http://www.biostathandbook.com/onewayanova.html\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.stats import f_oneway\n",
      "    \n",
      "    Here are some data [3]_ on a shell measurement (the length of the anterior\n",
      "    adductor muscle scar, standardized by dividing by length) in the mussel\n",
      "    Mytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;\n",
      "    Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a\n",
      "    much larger data set used in McDonald et al. (1991).\n",
      "    \n",
      "    >>> tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,\n",
      "    ...              0.0659, 0.0923, 0.0836]\n",
      "    >>> newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,\n",
      "    ...            0.0725]\n",
      "    >>> petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
      "    >>> magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,\n",
      "    ...            0.0689]\n",
      "    >>> tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]\n",
      "    >>> f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
      "    F_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)\n",
      "    \n",
      "    `f_oneway` accepts multidimensional input arrays.  When the inputs\n",
      "    are multidimensional and `axis` is not given, the test is performed\n",
      "    along the first axis of the input arrays.  For the following data, the\n",
      "    test is performed three times, once for each column.\n",
      "    \n",
      "    >>> a = np.array([[9.87, 9.03, 6.81],\n",
      "    ...               [7.18, 8.35, 7.00],\n",
      "    ...               [8.39, 7.58, 7.68],\n",
      "    ...               [7.45, 6.33, 9.35],\n",
      "    ...               [6.41, 7.10, 9.33],\n",
      "    ...               [8.00, 8.24, 8.44]])\n",
      "    >>> b = np.array([[6.35, 7.30, 7.16],\n",
      "    ...               [6.65, 6.68, 7.63],\n",
      "    ...               [5.72, 7.73, 6.72],\n",
      "    ...               [7.01, 9.19, 7.41],\n",
      "    ...               [7.75, 7.87, 8.30],\n",
      "    ...               [6.90, 7.97, 6.97]])\n",
      "    >>> c = np.array([[3.31, 8.77, 1.01],\n",
      "    ...               [8.25, 3.24, 3.62],\n",
      "    ...               [6.32, 8.81, 5.19],\n",
      "    ...               [7.48, 8.83, 8.91],\n",
      "    ...               [8.59, 6.01, 6.07],\n",
      "    ...               [3.07, 9.72, 7.48]])\n",
      "    >>> F, p = f_oneway(a, b, c)\n",
      "    >>> F\n",
      "    array([1.75676344, 0.03701228, 3.76439349])\n",
      "    >>> p\n",
      "    array([0.20630784, 0.96375203, 0.04733157])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 分散分析(ANOVA: analysis of variance)は実験における条件の違いが結果に影響するかどうかを判定する\n",
    "# 具体的には2標本以上の標本について期待値の同等性を検定する(2標本検定の拡張)\n",
    "# H0: μ1＝μ2＝・・・＝μa (a種類の実験方法で得られたデータ群の期待値)\n",
    "# H1: 異なる期待値が少なくとも1つ存在する\n",
    "# 分散分析の用語では、観測値に影響を与える設定のことを因子、各a種類の実験方法を水準という\n",
    "# 考えている因子数が1の場合の仮設検定の枠組みを1元配置分散分析という\n",
    "help(stats.f_oneway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67838dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 帰無仮説が正しい: 水準数は5, 各水準で10データ\n",
    "x1, x2, x3, x4, x5 = np.random.normal(size = 50).reshape(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fe9d42b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 0.36214194840392433\n",
      "pval: 0.8342307187731435\n"
     ]
    }
   ],
   "source": [
    "F, pval = stats.f_oneway(x1, x2, x3, x4, x5)\n",
    "print(\"F: {}\\npval: {}\".format(F, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb6e6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 帰無仮説は間違い: 水準数は6, 各水準は20データ\n",
    "x1, x2, x3, x4, x5, x6 = np.r_[np.random.normal(size = 100), np.random.normal(loc = 0.7, size = 20)].reshape(6, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c88a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 2.4623957238659973\n",
      "pval: 0.03700099363384216\n"
     ]
    }
   ],
   "source": [
    "F, pval = stats.f_oneway(x1, x2, x3, x4, x5, x6)\n",
    "print(\"F: {}\\npval: {}\".format(F, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0558433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ea374633",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9bbc7ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/Users/akito_harada/Documents/python/stats/ml/venv/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "64d4cca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 花の種類とガクの長さ(sepal length)の関係をANOVAで調べる\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cd678419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53dad950",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = iris.data[iris.target == 0, 0]\n",
    "x1 = iris.data[iris.target == 1, 0]\n",
    "x2 = iris.data[iris.target == 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "84dab739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c4ec9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 119.26450218450468\n",
      "pval: 1.6696691907693826e-31\n"
     ]
    }
   ],
   "source": [
    "F, pval = stats.f_oneway(x0, x1, x2)\n",
    "print(\"F: {}\\npval: {}\".format(F, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2fd4c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結論は花の種類が異なると、ガクの長さが異なるということ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
